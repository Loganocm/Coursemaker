```json
{
  "courseTitle": "The Essentials of Computer Organization and Architecture",
  "modules": [
    {
      "moduleTitle": "Module 1: Introduction to Computer Organization and Architecture",
      "notes": {
        "summary": "This module introduces the fundamental concepts of computer organization and architecture, essential for understanding how hardware interacts with software. Computer organization focuses on physical aspects like control signals and memory types, addressing 'how a computer works.' Computer architecture, conversely, deals with the logical design and behavior, including instruction sets and addressing modes, answering 'how to design a computer.' We explore the evolution of computing through historical 'generations,' from mechanical calculators to modern VLSI computers, including key figures like Babbage, Pascal, Atanasoff, Mauchly, Eckert, and Zuse. Moore's Law, which predicts the doubling of transistor density, is discussed along with its implications and limitations. The course examines the computer as a hierarchy of levels, from digital logic to high-level languages, explaining how each level abstracts complexity. We also delve into the foundational Von Neumann model and its limitations, contrasting it with non-Von Neumann and parallel processing models. Contemporary topics like cloud computing and multicore processors are introduced, along with a 'wading through the jargon' section to demystify common computer specifications. The role of standards organizations like IEEE and ISO in ensuring interoperability is highlighted.",
        "keywords": [
          "Computer Organization",
          "Computer Architecture",
          "CPU",
          "Memory",
          "I/O",
          "Moore's Law",
          "Von Neumann Model",
          "Cloud Computing",
          "Parallel Processors",
          "Generations",
          "Transistor",
          "VLSI",
          "Computer Level Hierarchy",
          "Instruction Set Architecture",
          "Standards Organizations"
        ]
      },
      "flashcards": [
        {
          "question": "What is the primary focus of Computer Organization?",
          "answer": "Computer Organization focuses on the physical aspects of a computer system, such as control signals, signaling methods, and memory types, addressing 'how a computer works.'"
        },
        {
          "question": "What is the primary focus of Computer Architecture?",
          "answer": "Computer Architecture focuses on the logical design and behavior of a computer system, including instruction sets, data types, and I/O mechanisms, addressing 'how to design a computer.'"
        },
        {
          "question": "Who is considered the 'Father of Computing' for his work on the Analytical Engine?",
          "answer": "Charles Babbage."
        },
        {
          "question": "What technology defined the First Generation of computers (1945–1953)?",
          "answer": "Vacuum tubes."
        },
        {
          "question": "What technology defined the Second Generation of computers (1954–1965)?",
          "answer": "Transistors."
        },
        {
          "question": "What technology defined the Third Generation of computers (1965–1980)?",
          "answer": "Integrated Circuits (ICs)."
        },
        {
          "question": "What does Moore's Law state?",
          "answer": "The density of transistors in an integrated circuit will double approximately every 18 months."
        },
        {
          "question": "What are the three main hardware systems in the Von Neumann model?",
          "answer": "Central Processing Unit (CPU), Main Memory System, and I/O System."
        },
        {
          "question": "What is the 'Von Neumann Bottleneck'?",
          "answer": "The single physical or logical path between main memory and the CPU's control unit, forcing alternation of instruction fetch and execution cycles."
        },
        {
          "question": "What is Cloud Computing?",
          "answer": "A general term for virtual computing platforms delivered as a service over the Internet, where users access resources without managing the underlying physical infrastructure."
        }
      ],
      "quiz": [
        {
          "question": "Which of the following best describes the difference between computer organization and computer architecture?",
          "options": {
            "A": "Organization focuses on high-level programming, while architecture focuses on low-level hardware.",
            "B": "Organization addresses physical aspects, while architecture focuses on logical aspects like instruction sets.",
            "C": "Architecture deals with how a computer works, while organization deals with how to design one.",
            "D": "They are synonymous terms with no significant difference."
          },
          "correctAnswer": "B"
        },
        {
          "question": "What was the primary technology used in the First Generation of electronic computers?",
          "options": {
            "A": "Transistors",
            "B": "Integrated Circuits",
            "C": "Vacuum Tubes",
            "D": "VLSI"
          },
          "correctAnswer": "C"
        },
        {
          "question": "Which concept suggests that a small amount of very fast memory can significantly improve overall system performance?",
          "options": {
            "A": "Moore's Law",
            "B": "The Von Neumann Bottleneck",
            "C": "Locality of Reference",
            "D": "Amdahl's Law"
          },
          "correctAnswer": "C"
        },
        {
          "question": "Which company introduced the first microprocessor, the 4004, in 1971?",
          "options": {
            "A": "IBM",
            "B": "Apple",
            "C": "Intel",
            "D": "Microsoft"
          },
          "correctAnswer": "C"
        }
      ]
    },
    {
      "moduleTitle": "Module 2: Data Representation in Computer Systems",
      "notes": {
        "summary": "This module explains how computers store and manipulate numerical and character data. It begins with positional numbering systems, covering binary (base 2), octal (base 8), and hexadecimal (base 16), along with methods for converting between these bases for both whole numbers and fractions. A significant portion is dedicated to signed integer representation, detailing Signed Magnitude, One's Complement, Two's Complement (the most common method for its arithmetic simplicity and single zero representation), and Excess-M representation. We explore binary arithmetic, including Booth's Algorithm for multiplication and the crucial distinction between carry and overflow flags. The module then moves to floating-point representation, explaining its components (sign, exponent, significand), the use of biased exponents and normalization. It highlights the inherent floating-point errors (overflow, underflow, precision loss) and introduces the widely adopted IEEE-754 standard for single and double precision, emphasizing its special values (zero, infinity, NaN). Finally, the module covers character codes, including Binary-Coded Decimal (BCD), EBCDIC, ASCII, and the international standard Unicode, which addresses limitations of earlier Latin-centric codes. It concludes with an overview of error detection and correction techniques, such as Cyclic Redundancy Check (CRC), Hamming Codes for single-bit errors, and Reed-Solomon codes for burst errors, illustrating the mathematical principles behind them.",
        "keywords": [
          "Data Representation",
          "Binary",
          "Hexadecimal",
          "Octal",
          "Radix",
          "Signed Integer Representation",
          "Signed Magnitude",
          "One's Complement",
          "Two's Complement",
          "Excess-M",
          "Booth's Algorithm",
          "Floating-Point Representation",
          "Significand",
          "Exponent",
          "IEEE-754",
          "Normalization",
          "Floating-Point Errors",
          "Character Codes",
          "BCD",
          "EBCDIC",
          "ASCII",
          "Unicode",
          "Error Detection",
          "Error Correction",
          "CRC",
          "Hamming Codes",
          "Reed-Solomon"
        ]
      },
      "flashcards": [
        {
          "question": "What is a 'radix' in a numbering system?",
          "answer": "The base of the numbering system, which determines the number of unique digits used (e.g., 10 for decimal, 2 for binary)."
        },
        {
          "question": "Which signed integer representation is most commonly used by computers?",
          "answer": "Two's Complement."
        },
        {
          "question": "What is the primary advantage of Two's Complement for computer arithmetic?",
          "answer": "It simplifies addition and subtraction, allowing them to be performed using the same hardware as unsigned numbers, and it has only one representation for zero."
        },
        {
          "question": "What is 'normalization' in floating-point representation?",
          "answer": "Adjusting the exponent so that the leftmost bit of the significand (mantissa) is always a 1 (for non-zero numbers), which effectively provides an extra bit of precision."
        },
        {
          "question": "What does IEEE-754 standardize?",
          "answer": "A standard for single-precision (32-bit) and double-precision (64-bit) floating-point numbers, defining formats, operations, and exception conditions."
        },
        {
          "question": "Why should the '==' operator be avoided when comparing floating-point numbers in programming?",
          "answer": "Due to inherent approximation and rounding errors in floating-point representation, two numbers that are mathematically equal might have slightly different binary representations, leading to false negatives with '=='."
        },
        {
          "question": "What is ASCII?",
          "answer": "American Standard Code for Information Interchange, a 7-bit character code widely used for representing text."
        },
        {
          "question": "What is Unicode's primary advantage over ASCII and EBCDIC?",
          "answer": "Unicode is a 16-bit (or larger) alphabet designed to encode the majority of characters in every written language, addressing the limitations of Latin-centric codes for international use."
        },
        {
          "question": "What is the main purpose of Cyclic Redundancy Check (CRC)?",
          "answer": "To detect errors in large blocks or streams of data, primarily in data communications, by mathematically deriving a checksum."
        },
        {
          "question": "What type of errors are Hamming Codes primarily designed to correct?",
          "answer": "Single-bit errors, often used in computer memory where random errors are likely."
        },
        {
          "question": "What is 'Hamming Distance'?",
          "answer": "The number of bit positions in which two code words differ, which determines a code's error-detecting and correcting capabilities."
        }
      ],
      "quiz": [
        {
          "question": "What is the decimal equivalent of the binary number 101101_2?",
          "options": {
            "A": "45",
            "B": "37",
            "C": "53",
            "D": "29"
          },
          "correctAnswer": "A"
        },
        {
          "question": "In an 8-bit Two's Complement system, what is the decimal value of 11111100_2?",
          "options": {
            "A": "-4",
            "B": "-124",
            "C": "252",
            "D": "-3"
          },
          "correctAnswer": "A"
        },
        {
          "question": "Which of the following is a disadvantage of Signed Magnitude representation?",
          "options": {
            "A": "It only represents positive numbers.",
            "B": "Arithmetic operations are simpler than with Two's Complement.",
            "C": "It has two representations for zero (+0 and -0).",
            "D": "It requires more bits to represent numbers than Two's Complement."
          },
          "correctAnswer": "C"
        },
        {
          "question": "What is a 'page fault' in the context of memory management?",
          "options": {
            "A": "An error caused by accessing an invalid memory address.",
            "B": "A condition where a requested memory page is not found in main memory and must be retrieved from disk.",
            "C": "A hardware failure in the memory controller.",
            "D": "An overflow condition in the memory address register."
          },
          "correctAnswer": "B"
        },
        {
          "question": "What is the primary benefit of using a biased exponent in floating-point representation?",
          "options": {
            "A": "It increases the overall precision of the number.",
            "B": "It allows for a simpler sign bit for the exponent.",
            "C": "It eliminates the need for a separate sign bit for the exponent and simplifies comparisons.",
            "D": "It ensures that all floating-point numbers are normalized."
          },
          "correctAnswer": "C"
        },
        {
          "question": "Which character encoding is a 16-bit international standard designed to represent characters from nearly all written languages?",
          "options": {
            "A": "ASCII",
            "B": "EBCDIC",
            "C": "BCD",
            "D": "Unicode"
          },
          "correctAnswer": "D"
        }
      ]
    },
    {
      "moduleTitle": "Module 3: Boolean Algebra and Digital Logic",
      "notes": {
        "summary": "This module introduces the fundamental concepts of Boolean algebra and digital logic, which are the bedrock of modern computer design. George Boole's symbolic logic provides a mathematical framework for manipulating binary values (0s and 1s), perfectly suited for representing the on/off states of electronic switches. We explore Boolean expressions, including the basic operators (AND, OR, NOT) and their truth tables, as well as more complex ones like XOR. Key Boolean identities, such as DeMorgan's Law, are presented as tools for simplifying expressions, which is crucial for reducing the complexity and cost of physical circuits. Logic gates (AND, OR, NOT, XOR, NAND, NOR) are introduced as the physical implementations of these Boolean operations. The module highlights NAND and NOR gates as 'universal gates,' meaning any digital circuit can be constructed using only one type, simplifying integrated circuit manufacturing. Digital components are categorized into combinational circuits (whose outputs depend solely on current inputs, e.g., half-adders, full-adders, decoders, multiplexers, ALUs) and sequential circuits (whose outputs depend on current inputs and past states, thus possessing memory). Sequential circuits require clocks for synchronization and are built from storage elements called flip-flops (SR, JK, D types). The behavior of sequential circuits is often depicted using Finite State Machines (FSMs), including Moore and Mealy machines. The module demonstrates how to design circuits from problem descriptions to simplified Boolean expressions, and finally to logic diagrams. It also touches on practical applications such as convolutional coding and the Viterbi detector in error correction.",
        "keywords": [
          "Boolean Algebra",
          "Digital Logic",
          "Logic Gates",
          "AND Gate",
          "OR Gate",
          "NOT Gate",
          "XOR Gate",
          "NAND Gate",
          "NOR Gate",
          "Universal Gates",
          "Truth Table",
          "Boolean Identities",
          "DeMorgan's Law",
          "Combinational Circuits",
          "Sequential Circuits",
          "Half-Adder",
          "Full-Adder",
          "Decoder",
          "Multiplexer",
          "ALU",
          "Flip-Flop",
          "SR Flip-Flop",
          "JK Flip-Flop",
          "D Flip-Flop",
          "Clock",
          "Finite State Machine (FSM)",
          "Moore Machine",
          "Mealy Machine",
          "Karnaugh Map"
        ]
      },
      "flashcards": [
        {
          "question": "What is the purpose of Boolean algebra in computer science?",
          "answer": "It provides a mathematical framework for manipulating binary values (0s and 1s), which directly corresponds to the on/off states of electronic switches used in digital circuits."
        },
        {
          "question": "Which Boolean identity states that (xy)' = x' + y'?",
          "answer": "DeMorgan's Law."
        },
        {
          "question": "What makes NAND and NOR gates 'universal gates'?",
          "answer": "Any electronic circuit can be constructed using only NAND gates or only NOR gates."
        },
        {
          "question": "What is the key difference between a combinational circuit and a sequential circuit?",
          "answer": "Combinational circuit outputs depend only on current inputs (no memory), while sequential circuit outputs depend on current inputs and previous states (they have memory)."
        },
        {
          "question": "What is the primary function of a Half-Adder?",
          "answer": "It adds two binary digits and produces a sum and a carry out."
        },
        {
          "question": "What is a flip-flop?",
          "answer": "A basic storage element of sequential circuits that can maintain a stable output state even after input signals are removed; it is edge-triggered."
        },
        {
          "question": "What is a D flip-flop primarily used for?",
          "answer": "To store a single bit of data, with its output 'Q' directly reflecting the value of its input 'D' when clocked."
        },
        {
          "question": "What are Finite State Machines (FSMs) used to depict?",
          "answer": "The behavior of flip-flops and sequential circuits, showing states and transitions."
        },
        {
          "question": "What is a Moore Machine?",
          "answer": "A type of Finite State Machine where the output is associated with each state."
        },
        {
          "question": "What is a Mealy Machine?",
          "answer": "A type of Finite State Machine where the output is associated with each transition."
        }
      ],
      "quiz": [
        {
          "question": "Which of the following Boolean expressions is equivalent to F(x, y) = x + xy using Boolean identities?",
          "options": {
            "A": "xy",
            "B": "x",
            "C": "y",
            "D": "x + y"
          },
          "correctAnswer": "B"
        },
        {
          "question": "Which type of logic gate provides a 1 output if its inputs are different and a 0 output if its inputs are the same?",
          "options": {
            "A": "AND",
            "B": "OR",
            "C": "NOT",
            "D": "XOR"
          },
          "correctAnswer": "D"
        },
        {
          "question": "A circuit whose output is ALWAYS based ENTIRELY on the given inputs, with no memory, is called a(n):",
          "options": {
            "A": "Sequential Circuit",
            "B": "Flip-Flop",
            "C": "Combinational Circuit",
            "D": "Finite State Machine"
          },
          "correctAnswer": "C"
        },
        {
          "question": "Which of the following is NOT a common type of flip-flop?",
          "options": {
            "A": "SR Flip-Flop",
            "B": "JK Flip-Flop",
            "C": "D Flip-Flop",
            "D": "AND Flip-Flop"
          },
          "correctAnswer": "D"
          },
          "correctAnswer": "D"
        }
      ]
    },
    {
      "moduleTitle": "Module 4: MARIE: An Introduction to a Simple Computer",
      "notes": {
        "summary": "This module introduces MARIE (Machine Architecture that is Really Intuitive and Easy), a simplified computer architecture designed for pedagogical purposes, to illustrate fundamental computer organization concepts. We first review the basic components of a CPU: the Arithmetic Logic Unit (ALU), registers, and the Control Unit, along with the role of buses and clocks in data transfer and synchronization. The module details the input/output (I/O) subsystem and memory organization. The core of MARIE's operation is the fetch-decode-execute cycle, which explains how instructions are retrieved from memory, interpreted, operands fetched, executed by the ALU, and results stored. Interrupts, which can alter the normal instruction flow, are also discussed. We then explore assembly language programming in MARIE, understanding the one-to-one relationship between symbolic assembly instructions and binary machine code, and the role of assemblers. A significant comparison is made between hardwired control units (faster but less flexible) and microprogrammed control units (slower but highly flexible and easier to modify), highlighting the trade-offs in CPU design. Finally, the module provides a brief introduction to real-world architectures like Intel (an example of a CISC – Complex Instruction Set Computer) and MIPS (an example of a RISC – Reduced Instruction Set Computer), outlining their key characteristics and how they differ from the simplified MARIE model, particularly concerning the number of registers and instruction complexity.",
        "keywords": [
          "MARIE Architecture",
          "CPU",
          "ALU",
          "Registers",
          "Control Unit",
          "Buses",
          "Clocks",
          "I/O Subsystem",
          "Memory Organization",
          "Fetch-Decode-Execute Cycle",
          "Instruction Register",
          "Program Counter",
          "Accumulator",
          "Assembly Language",
          "Assembler",
          "Hardwired Control",
          "Microprogrammed Control",
          "CISC",
          "RISC",
          "Intel Architecture",
          "MIPS Architecture",
          "Stack"
        ]
      },
      "flashcards": [
        {
          "question": "What is the primary function of the Accumulator (AC) register in MARIE?",
          "answer": "It is the primary general-purpose register in MARIE, used for all arithmetic and logic operations, and holds the data being processed."
        },
        {
          "question": "What is the purpose of the Program Counter (PC) in a CPU?",
          "answer": "It holds the address of the next instruction to be fetched from memory."
        },
        {
          "question": "List the four main steps of the fetch-decode-execute cycle.",
          "answer": "1. Fetch instruction. 2. Decode instruction. 3. Fetch operands. 4. Execute instruction and store results."
        },
        {
          "question": "What is the key advantage of microprogrammed control over hardwired control?",
          "answer": "Microprogrammed control is more flexible, allowing the instruction set to be easily modified or extended by updating the microprogram, without requiring hardware changes."
        },
        {
          "question": "What does CISC stand for and what is its main characteristic?",
          "answer": "Complex Instruction Set Computer. It features a large number of variable-length, often complex instructions that can perform multiple operations."
        },
        {
          "question": "What does RISC stand for and what is its main characteristic?",
          "answer": "Reduced Instruction Set Computer. It uses a smaller, simplified instruction set with fixed-length instructions, aiming for faster execution and easier pipelining."
        },
        {
          "question": "What is the purpose of a 'stack' data structure in computer architecture?",
          "answer": "A LIFO (Last-In, First-Out) data structure used for temporary storage of data, such as intermediate results, function parameters, and return addresses during procedure calls."
        },
        {
          "question": "How do interrupts affect the fetch-decode-execute cycle?",
          "answer": "Interrupts can temporarily halt or alter the normal flow of the fetch-decode-execute cycle to allow the CPU to respond to an event, typically at the beginning of a new instruction cycle."
        },
        {
          "question": "What is the main difference between machine language and assembly language?",
          "answer": "Machine language consists of binary instructions directly executable by the CPU, while assembly language uses symbolic mnemonics that have a one-to-one correspondence to machine instructions and must be translated by an assembler."
        },
        {
          "question": "Name two types of registers typically found in a CPU, besides the Accumulator and Program Counter.",
          "answer": "Memory Address Register (MAR), Memory Buffer Register (MBR), Instruction Register (IR), Input Register, Output Register (in MARIE)."
        }
      ],
      "quiz": [
        {
          "question": "Which component of the CPU is responsible for coordinating the sequencing of steps in the fetch-decode-execute cycle?",
          "options": {
            "A": "Arithmetic Logic Unit (ALU)",
            "B": "Registers",
            "C": "Control Unit",
            "D": "Main Memory"
          },
          "correctAnswer": "C"
        },
        {
          "question": "In MARIE, what is the size of a memory word and an instruction?",
          "options": {
            "A": "8 bits",
            "B": "16 bits",
            "C": "32 bits",
            "D": "64 bits"
          },
          "correctAnswer": "B"
        },
        {
          "question": "Which type of control unit is generally faster but less flexible for instruction set modifications?",
          "options": {
            "A": "Microprogrammed control",
            "B": "Hardwired control",
            "C": "Accumulator control",
            "D": "RISC control"
          },
          "correctAnswer": "B"
        },
        {
          "question": "Which of the following characteristics is typically associated with RISC architectures?",
          "options": {
            "A": "Many complex, variable-length instructions",
            "B": "Complexity handled primarily by microcode",
            "C": "Fixed-length instructions and simpler designs for faster pipelining",
            "D": "Extensive use of memory-to-memory operations"
          },
          "correctAnswer": "C"
        }
      ]
    },
    {
      "moduleTitle": "Module 5: A Closer Look at Instruction Set Architectures",
      "notes": {
        "summary": "This module delves deeper into Instruction Set Architectures (ISAs), which define the interface between hardware and software. We examine how instruction formats are designed, considering factors like operand storage (stack, accumulator, or general-purpose registers – GPRs, which are most common), the number of explicit operands (zero to three), and their locations (register-to-register, register-to-memory, memory-to-memory). The concept of 'endianness' (Little Endian vs. Big Endian) is explained, detailing how multi-byte data is stored in memory. We explore how expanding opcodes allow for a rich instruction set while maintaining manageable instruction lengths. The module categorizes various instruction types, including data movement, arithmetic, Boolean logic, bit manipulation (shifts, rotates), input/output, and control transfer (branches, calls). The principle of 'instruction set orthogonality' is introduced, emphasizing consistent and independent instruction design. A significant section is dedicated to addressing modes, which specify how an operand's location is determined (e.g., immediate, direct, indirect, indexed, based, stack). Finally, the module covers instruction pipelining, a crucial technique for achieving Instruction-Level Parallelism (ILP) by overlapping instruction stages. It discusses pipeline conflicts (resource, data dependencies, branch hazards) and introduces advanced ILP approaches like superscalar, VLIW, and EPIC architectures. Real-world ISAs, including Intel (CISC), MIPS (RISC), Java Virtual Machine (JVM), and ARM, are presented to illustrate these concepts.",
        "keywords": [
          "Instruction Set Architecture (ISA)",
          "Instruction Formats",
          "Operand Storage",
          "Stack Architecture",
          "Accumulator Architecture",
          "General-Purpose Register (GPR) Architecture",
          "Endianness",
          "Little Endian",
          "Big Endian",
          "Expanding Opcodes",
          "Reverse Polish Notation (RPN)",
          "Instruction Types",
          "Orthogonality",
          "Addressing Modes",
          "Immediate Addressing",
          "Direct Addressing",
          "Indirect Addressing",
          "Indexed Addressing",
          "Register Indirect Addressing",
          "Instruction Pipelining",
          "Instruction-Level Parallelism (ILP)",
          "Pipeline Hazards",
          "Superscalar",
          "VLIW (Very Long Instruction Word)",
          "EPIC (Explicitly Parallel Instruction Computing)",
          "Intel Architecture",
          "MIPS Architecture",
          "Java Virtual Machine (JVM)",
          "ARM Architecture"
        ]
      },
      "flashcards": [
        {
          "question": "What is 'endianness' in computer architecture?",
          "answer": "It refers to the byte order in which multi-byte data elements (like integers) are stored in memory, specifically whether the most significant byte (Big Endian) or least significant byte (Little Endian) is stored at the lowest memory address."
        },
        {
          "question": "Describe a 'Load-Store Architecture'.",
          "answer": "An architecture where only 'load' and 'store' instructions can access memory; all other operations must use registers for their operands. This necessitates a large register file."
        },
        {
          "question": "What is Reverse Polish Notation (RPN) used for?",
          "answer": "It's a mathematical notation where operators follow their operands (postfix notation), which is highly efficient for evaluating arithmetic expressions using a stack-based architecture."
        },
        {
          "question": "What is the purpose of 'expanding opcodes'?",
          "answer": "It's a compromise in instruction design that allows for a rich set of operation codes (opcodes) while keeping the overall instruction length manageable by varying the opcode length based on the number of operands."
        },
        {
          "question": "What is 'instruction pipelining'?",
          "answer": "A technique that overlaps the stages of the fetch-decode-execute cycle, allowing multiple instructions to be in different stages of execution simultaneously, thereby speeding up overall instruction throughput."
        },
        {
          "question": "Name three common types of pipeline conflicts (hazards).",
          "answer": "Resource conflicts (structural hazards), data dependencies, and conditional branch statements."
        },
        {
          "question": "What is a 'superscalar' processor?",
          "answer": "A processor design that includes multiple execution units (e.g., ALUs) and can issue more than one instruction per clock cycle, achieving instruction-level parallelism."
        },
        {
          "question": "How does a 'VLIW' (Very Long Instruction Word) processor achieve parallelism?",
          "answer": "It relies heavily on the compiler to pack multiple independent instructions into one fixed-length 'very long instruction,' which then dictates actions for multiple execution units simultaneously."
        },
        {
          "question": "What is the primary role of the Java Virtual Machine (JVM)?",
          "answer": "The JVM is a software emulation of a real machine that executes Java bytecodes, providing platform independence by translating bytecodes to native machine instructions at runtime."
        },
        {
          "question": "Which architecture is dominant in mobile and embedded systems due to its efficiency and low power consumption?",
          "answer": "ARM (Advanced RISC Machine)."
        },
        {
          "question": "What is 'orthogonality' in an instruction set?",
          "answer": "It means the instruction set is complete (each unique function) and consistent, with no restrictions on operand/opcode relationships or special registers for particular instructions, simplifying compiler writing."
        }
      ],
      "quiz": [
        {
          "question": "If the hexadecimal value 0x1234ABCD is stored in a Little Endian system, what byte would be found at the lowest memory address?",
          "options": {
            "A": "0x12",
            "B": "0x34",
            "C": "0xAB",
            "D": "0xCD"
          },
          "correctAnswer": "D"
        },
        {
          "question": "Which type of CPU internal storage architecture is most widely accepted and provides the most flexibility for compilers?",
          "options": {
            "A": "Stack Architecture",
            "B": "Accumulator Architecture",
            "C": "General-Purpose Register (GPR) Architecture",
            "D": "Memory-Memory Architecture"
          },
          "correctAnswer": "C"
        },
        {
          "question": "The RPN expression '5 3 + 2 *' evaluates to:",
          "options": {
            "A": "16",
            "B": "13",
            "C": "10",
            "D": "8"
          },
          "correctAnswer": "A"
        },
        {
          "question": "Which of the following is considered a major pipeline conflict or hazard?",
          "options": {
            "A": "Increased clock speed",
            "B": "Abundant registers",
            "C": "Data dependencies",
            "D": "Fixed-length instructions"
          },
          "correctAnswer": "C"
        }
      ]
    },
    {
      "moduleTitle": "Module 6: Memory Hierarchy and Virtual Memory",
      "notes": {
        "summary": "This module thoroughly explores computer memory, emphasizing the memory hierarchy as a critical strategy to balance performance and cost. It begins by classifying memory types: volatile RAM (Dynamic RAM - DRAM for main memory, Static RAM - SRAM for cache) and non-volatile ROM (PROM, EPROM, EEPROM, and Flash Memory). The memory hierarchy positions faster, smaller, and more expensive memories (registers, cache) closer to the CPU, while slower, larger, and cheaper memories (main memory, secondary storage like disks, and tertiary/off-line storage) are farther away. The success of this hierarchy relies on the 'locality of reference' principle, which includes temporal, spatial, and sequential locality. Cache memory, a small, fast buffer, is detailed with its mapping schemes (direct mapped, fully associative, set associative), which determine how main memory blocks are placed and located in cache. Various replacement policies (LRU, FIFO, Random) are discussed for when the cache is full, along with write policies (write-through, write-back) for maintaining consistency with main memory. The module differentiates between instruction and data caches and introduces multilevel caches (L1, L2, L3). Finally, it covers virtual memory, a technique that extends available address space by using disk as an extension of RAM. Paging, the most common implementation, involves fixed-size pages and page frames, using a page table for address translation. Page faults, which occur when a requested page is not in main memory, are explained, as is the role of Translation Look-aside Buffers (TLBs) in speeding up page table lookups. Segmentation, an alternative to paging with variable-length logical units, and the combination of paging with segmentation are also presented, highlighting their advantages and disadvantages.",
        "keywords": [
          "Memory Hierarchy",
          "RAM",
          "DRAM",
          "SRAM",
          "ROM",
          "PROM",
          "EPROM",
          "EEPROM",
          "Flash Memory",
          "Locality of Reference",
          "Temporal Locality",
          "Spatial Locality",
          "Sequential Locality",
          "Cache Memory",
          "Direct Mapped Cache",
          "Fully Associative Cache",
          "Set Associative Cache",
          "Replacement Policy",
          "Least Recently Used (LRU)",
          "First-In, First-Out (FIFO)",
          "Write Policy",
          "Write-through",
          "Write-back",
          "Effective Access Time (EAT)",
          "Hit Rate",
          "Miss Penalty",
          "Virtual Memory",
          "Paging",
          "Page Frame",
          "Page Table",
          "Page Fault",
          "Translation Look-aside Buffer (TLB)",
          "Segmentation",
          "Internal Fragmentation",
          "External Fragmentation"
        ]
      },
      "flashcards": [
        {
          "question": "What is the primary difference between DRAM and SRAM?",
          "answer": "DRAM (Dynamic RAM) requires periodic refreshing to retain data and is denser/cheaper, typically used for main memory. SRAM (Static RAM) holds data as long as power is supplied without refreshing and is faster/more expensive, used for cache."
        },
        {
          "question": "What does 'locality of reference' refer to in memory systems?",
          "answer": "A principle stating that programs tend to access memory in clusters, either by revisiting recently accessed items (temporal locality), accessing items near recently accessed ones (spatial locality), or accessing instructions sequentially (sequential locality)."
        },
        {
          "question": "Explain 'direct mapped cache' mapping.",
          "answer": "Each main memory block can map to only one specific cache block location, determined by a modular arithmetic function (Block Y = Block X mod N), which can lead to conflict misses."
        },
        {
          "question": "Explain 'set associative cache' mapping.",
          "answer": "A compromise between direct mapped and fully associative, where each main memory block maps to a specific 'set' of cache blocks, and then an associative search is performed within that set."
        },
        {
          "question": "What is the difference between a 'write-through' and a 'write-back' cache policy?",
          "answer": "Write-through updates both cache and main memory simultaneously on every write, ensuring consistency. Write-back updates main memory only when a modified cache block is evicted, providing faster write performance but risking inconsistency if the system crashes."
        },
        {
          "question": "What is 'virtual memory'?",
          "answer": "A memory management technique that uses secondary storage (typically hard disk) as an extension of main memory, allowing programs to use a larger address space than physically available RAM."
        },
        {
          "question": "What is a 'page table' used for in paging?",
          "answer": "A data structure, typically residing in main memory, that maps virtual page numbers to their corresponding physical page frame numbers."
        },
        {
          "question": "What is a 'Translation Look-aside Buffer (TLB)'?",
          "answer": "A small, high-speed cache that stores recent virtual-to-physical address translations (page number to frame number mappings) to speed up page table lookups."
        },
        {
          "question": "What is 'internal fragmentation' in paging?",
          "answer": "Unusable memory space within a page frame that is allocated to a process but not entirely filled by the process's data, leading to wasted space."
        },
        {
          "question": "What is 'external fragmentation' in segmentation?",
          "answer": "Memory becoming broken into many small, non-contiguous, unusable chunks of free space that are too small to satisfy new allocation requests, even if the total free space is sufficient."
        }
      ],
      "quiz": [
        {
          "question": "Which type of RAM is typically used for cache memory due to its higher speed and cost?",
          "options": {
            "A": "DRAM",
            "B": "SRAM",
            "C": "Flash Memory",
            "D": "PROM"
          },
          "correctAnswer": "B"
        },
        {
          "question": "When a CPU requests data, and it is NOT found in the cache, this is called a(n):",
          "options": {
            "A": "Hit",
            "B": "Miss",
            "C": "Penalty",
            "D": "Stall"
          },
          "correctAnswer": "B"
        },
        {
          "question": "Which cache replacement policy removes the block that has been in the cache for the longest time?",
          "options": {
            "A": "LRU (Least Recently Used)",
            "B": "FIFO (First-In, First-Out)",
            "C": "Random",
            "D": "Optimal"
          },
          "correctAnswer": "B"
        },
        {
          "question": "What is the primary function of virtual memory?",
          "options": {
            "A": "To increase the physical speed of RAM.",
            "B": "To allow programs to execute without needing any RAM.",
            "C": "To use hard disk space as an extension of RAM, increasing the apparent address space.",
            "D": "To provide permanent storage for program execution."
          },
          "correctAnswer": "C"
        }
      ]
    },
    {
      "moduleTitle": "Module 7: Input/Output and Storage Systems",
      "notes": {
        "summary": "This module explores the critical role of Input/Output (I/O) and storage systems in overall computer performance, often the source of perceived system slowness. It introduces Amdahl's Law as a tool to quantify the maximum potential speedup when only a portion of a system is improved. Various I/O control methods are detailed, including Programmed I/O (CPU continuously polls), Interrupt-Driven I/O (devices signal CPU), Memory-Mapped I/O (I/O devices share address space with memory), Direct Memory Access (DMA - CPU offloads transfers to a controller), and Channel I/O (intelligent I/O processors handle transfers in large systems). The module distinguishes between character I/O and block I/O and discusses synchronous vs. asynchronous I/O bus operations. Data transmission modes (parallel and serial) are compared for efficiency over distance. A significant portion focuses on magnetic disk technology, covering rigid disk drives (platters, heads, seek time, rotational delay, access time) and the advantages/disadvantages of Solid State Drives (SSDs). Optical disks (CD-ROM, DVD, Blu-Ray) and magnetic tape (serpentine, helical scan, LTO) are also covered. The module then delves into RAID (Redundant Array of Independent Disks) levels (0, 1, 2, 3, 4, 5, 6, DP) and hybrid systems, explaining how they enhance data reliability and performance through striping and parity. It concludes with a look at future storage technologies and a 'Focus on Data Compression,' explaining statistical coding (Huffman, arithmetic), dictionary systems (LZ77, LZ78, LZW), and industry standards like GIF, PNG, JPEG, and MP3, emphasizing how they reduce redundancy.",
        "keywords": [
          "Input/Output (I/O)",
          "Amdahl's Law",
          "Programmed I/O",
          "Interrupt-Driven I/O",
          "Memory-Mapped I/O",
          "Direct Memory Access (DMA)",
          "Channel I/O",
          "Character I/O",
          "Block I/O",
          "Parallel Data Transmission",
          "Serial Data Transmission",
          "Magnetic Disk Technology",
          "Rigid Disk Drive",
          "Solid State Drive (SSD)",
          "Seek Time",
          "Rotational Delay",
          "Access Time",
          "Transfer Time",
          "Optical Disk",
          "CD-ROM",
          "DVD",
          "Blu-Ray",
          "Magnetic Tape",
          "Linear Tape Open (LTO)",
          "RAID (Redundant Array of Independent Disks)",
          "RAID Level 0",
          "RAID Level 1",
          "RAID Level 5",
          "RAID DP",
          "Data Compression",
          "Huffman Coding",
          "Arithmetic Coding",
          "Ziv-Lempel (LZ)",
          "LZW Compression",
          "JPEG Compression",
          "MP3 Compression",
          "Entropy",
          "Redundancy"
        ]
      },
      "flashcards": [
        {
          "question": "What is Amdahl's Law used for?",
          "answer": "To quantify the overall speedup of a computer system when only a fraction of its workload benefits from an improvement in a component."
        },
        {
          "question": "Describe 'Programmed I/O'.",
          "answer": "The simplest I/O control method where the CPU continuously monitors (polls) an I/O device's status register to check if data is ready, leading to 'busy waiting'."
        },
        {
          "question": "What is the primary advantage of 'Interrupt-Driven I/O' over 'Programmed I/O'?",
          "answer": "It allows the CPU to perform other useful work until an I/O device signals that it needs attention via an interrupt, rather than constantly polling."
        },
        {
          "question": "What is 'DMA' (Direct Memory Access)?",
          "answer": "An I/O control method where a specialized DMA controller handles data transfers between I/O devices and main memory directly, freeing the CPU from this task."
        },
        {
          "question": "What are the main performance metrics for a rigid disk drive?",
          "answer": "Seek time (time to position heads), rotational delay (time for sector to spin under heads), and transfer time (time to read/write data)."
        },
        {
          "question": "What is the key advantage of Solid State Drives (SSDs) over traditional HDDs?",
          "answer": "Significantly faster access and transfer times, lower power consumption, and greater durability due to using flash memory instead of spinning platters."
        },
        {
          "question": "What is the purpose of RAID Level 0 (Drive Spanning/Striping)?",
          "answer": "It stripes data across multiple disk surfaces for maximum performance (especially read/write speed) but provides no data redundancy or fault tolerance."
        },
        {
          "question": "Which RAID level provides mirroring for the best failure protection, at the cost of doubling disk requirements?",
          "answer": "RAID Level 1."
        },
        {
          "question": "Which RAID level is known for distributing parity information across all drives, offering a good balance of performance and fault tolerance for commercial applications?",
          "answer": "RAID Level 5."
        },
        {
          "question": "What is 'Huffman Coding' in data compression?",
          "answer": "A statistical coding method that assigns variable-length codes to input symbols, with more frequently occurring symbols receiving shorter codes to minimize redundancy."
        }
      ],
      "quiz": [
        {
          "question": "A system spends 80% of its time on a component that is improved by a factor of 4. According to Amdahl's Law, what is the overall system speedup?",
          "options": {
            "A": "1.25x",
            "B": "2.5x",
            "C": "3.33x",
            "D": "4.0x"
          },
          "correctAnswer": "B"
        },
        {
          "question": "Which I/O control method is best suited for large, multiuser systems like mainframes and utilizes dedicated I/O processors?",
          "options": {
            "A": "Programmed I/O",
            "B": "Interrupt-Driven I/O",
            "C": "Direct Memory Access (DMA)",
            "D": "Channel I/O"
          },
          "correctAnswer": "D"
        },
        {
          "question": "Which component is NOT a physical consideration for rigid disk drive performance?",
          "options": {
            "A": "Seek time",
            "B": "Rotational delay",
            "C": "Access time",
            "D": "Disk scheduling algorithm"
          },
          "correctAnswer": "D"
        },
        {
          "question": "Which data compression method is 'lossy' and specifically designed for photographic images?",
          "options": {
            "A": "Huffman Coding",
            "B": "LZW Compression (used in GIF)",
            "C": "JPEG Compression",
            "D": "PNG Compression"
          },
          "correctAnswer": "C"
        }
      ]
    },
    {
      "moduleTitle": "Module 8: System Software and Database Concepts",
      "notes": {
        "summary": "This module explores system software, which acts as the crucial interface between applications and hardware, abstracting low-level complexities. The operating system (OS) is introduced as the foundation of all system software, managing processes, resources, and protection. We trace the history of OS evolution from early manual operation to batch processing, multiprogramming, timesharing, and modern real-time, multiprocessor, and distributed systems, noting how OS advances mirror hardware improvements. Key OS design factors include the kernel (monolithic vs. microkernel architectures) and essential OS services like human interfaces (CLI, GUI), process management (scheduling, context switching, multitasking, multithreading), resource management (memory, I/O), and security/protection. The module then examines 'protected environments' such as Virtual Machines (VMs), Subsystems, and Logical Partitions (LPARs), explaining their benefits for isolation, security, and server consolidation. Programming tools are also covered, including assemblers (for assembly language), link editors (linkers) for combining program files, Dynamic Link Libraries (DLLs) for runtime linking, and compilers (multi-phase translation) versus interpreters. Java is presented as a unique case, using a Java Virtual Machine (JVM) to achieve platform independence through bytecode interpretation. Finally, the module delves into database software, explaining Database Management Systems (DBMSs) for data consistency and integrity, their use of logical and physical schemas, and the critical ACID properties (Atomicity, Consistency, Isolation, Durability) for transaction management. It illustrates how transaction managers prevent race conditions through locking and discusses the role of data logging and N-tiered architectures.",
        "keywords": [
          "System Software",
          "Operating System (OS)",
          "Kernel",
          "Microkernel",
          "Monolithic Kernel",
          "Batch Processing",
          "Multiprogramming",
          "Timesharing",
          "Real-Time System",
          "Multiprocessor System",
          "Distributed System",
          "CLI",
          "GUI",
          "Process Management",
          "Context Switch",
          "Multitasking",
          "Multithreading",
          "Virtual Machine (VM)",
          "Subsystem",
          "Logical Partition (LPAR)",
          "Server Consolidation",
          "Assembler",
          "Link Editor",
          "Dynamic Link Library (DLL)",
          "Compiler",
          "Interpreter",
          "Java Virtual Machine (JVM)",
          "Bytecode",
          "Database Management System (DBMS)",
          "Logical Schema",
          "Physical Schema",
          "ACID Properties",
          "Atomicity",
          "Consistency",
          "Isolation",
          "Durability",
          "Race Condition",
          "Deadlock",
          "Transaction Manager",
          "N-Tiered Architecture"
        ]
      },
      "flashcards": [
        {
          "question": "What is the 'kernel' in an operating system?",
          "answer": "The core, continuously executing part of the OS, responsible for fundamental functions like scheduling, memory management, protection, and handling interrupts."
        },
        {
          "question": "What is 'multiprogramming'?",
          "answer": "The concurrent execution of multiple processes by a single CPU, where the CPU rapidly switches between them to give the illusion of simultaneous execution."
        },
        {
          "question": "What is a 'Virtual Machine' (VM)?",
          "answer": "A self-contained operating environment that simulates a separate physical machine, allowing different operating systems or multiple instances of the same OS to run concurrently on a single physical host."
        },
        {
          "question": "What is 'server consolidation'?",
          "answer": "The practice of combining numerous smaller servers into a single larger system, often using virtualization (VMs, LPARs), to reduce management overhead, energy consumption, and physical space."
        },
        {
          "question": "What is the primary function of a 'compiler'?",
          "answer": "To translate an entire program's source code written in a high-level language into machine code or bytecode that can be executed by a computer."
        },
        {
          "question": "What is the primary function of an 'interpreter'?",
          "answer": "To translate and execute a program's source code one line or statement at a time, without producing a separate executable file."
        },
        {
          "question": "What are 'Dynamic Link Libraries (DLLs)'?",
          "answer": "Collections of binary objects that are linked to a program at runtime (when the program or module is first invoked), rather than at compile time, saving disk space and simplifying updates."
        },
        {
          "question": "What is the 'Java Virtual Machine (JVM)'?",
          "answer": "A software layer that interprets Java bytecode into native machine instructions, enabling Java programs to run on any platform for which a JVM exists ('write once, run anywhere')."
        },
        {
          "question": "List the four ACID properties of database transactions.",
          "answer": "Atomicity, Consistency, Isolation, and Durability."
        },
        {
          "question": "What is a 'race condition' in database management?",
          "answer": "A situation where the final state of data in a database depends on the arbitrary order in which concurrent transactions complete their operations, potentially leading to incorrect or inconsistent results."
        }
      ],
      "quiz": [
        {
          "question": "Which of the following OS kernel types typically offers better optimization for specific hardware but is less portable?",
          "options": {
            "A": "Microkernel",
            "B": "Monolithic Kernel",
            "C": "Hypervisor",
            "D": "Client-Server Kernel"
          },
          "correctAnswer": "B"
        },
        {
          "question": "When a CPU switches from one process to another, the act of saving the state of the current process and restoring the state of another is called:",
          "options": {
            "A": "Multitasking",
            "B": "Multithreading",
            "C": "Context Switching",
            "D": "Process Spooling"
          },
          "correctAnswer": "C"
        },
        {
          "question": "Which phase of compilation typically involves building a parse/syntax tree and checking for illegal language constructions?",
          "options": {
            "A": "Lexical Analysis",
            "B": "Syntax Analysis",
            "C": "Semantic Analysis",
            "D": "Code Generation"
          },
          "correctAnswer": "B"
        },
        {
          "question": "The ACID property of a database transaction that ensures all updates comply with data element constraints is:",
          "options": {
            "A": "Atomicity",
            "B": "Consistency",
            "C": "Isolation",
            "D": "Durability"
          },
          "correctAnswer": "B"
        }
      ]
    },
    {
      "moduleTitle": "Module 9: Alternative and Emerging Architectures",
      "notes": {
        "summary": "This module explores various alternative computer architectures that go beyond traditional uniprocessor designs, driven by the pursuit of higher performance and new computational paradigms. We begin with the evolution of RISC (Reduced Instruction Set Computer) philosophy, contrasting it with CISC (Complex Instruction Set Computer) and highlighting RISC innovations like register window sets and its re-emergence in embedded systems. Flynn's Taxonomy provides a fundamental classification of architectures based on instruction and data streams (SISD, SIMD, MISD, MIMD), with detailed refinements for MIMD systems like Symmetric Multiprocessors (SMPs) and Massively Parallel Processors (MPPs). Various interconnection networks (static like mesh and hypercube, and dynamic like bus-based and switching networks) are examined as crucial components for communication in parallel systems. The module delves into Shared Memory Multiprocessors (SMMs), including UMA and NUMA machines, and discusses the critical challenge of cache coherence and its solutions (snoopy caches, write policies). Distributed computing, including grid computing (like BOINC and SETI@Home) and the concept of transparency in ubiquitous computing, is also explored, along with supporting technologies like RPCs and SOAP, and its relation to Cloud computing. Finally, we venture into less conventional parallel processing approaches such as dataflow computing (where data availability drives instruction execution), neural networks (inspired by the human brain for pattern recognition and learning), and systolic arrays (rhythmic data circulation through simple processors for specialized tasks). The module concludes with a forward-looking discussion on emerging computing paradigms like optical, biological, DNA, and the revolutionary potential of quantum computing (using qubits and superposition for quantum parallelism), along with the theoretical concept of technological singularity.",
        "keywords": [
          "Alternative Architectures",
          "RISC (Reduced Instruction Set Computer)",
          "CISC (Complex Instruction Set Computer)",
          "Register Window Sets",
          "Flynn's Taxonomy",
          "SISD (Single Instruction, Single Data)",
          "SIMD (Single Instruction, Multiple Data)",
          "MISD (Multiple Instruction, Single Data)",
          "MIMD (Multiple Instruction, Multiple Data)",
          "Symmetric Multiprocessor (SMP)",
          "Massively Parallel Processor (MPP)",
          "Distributed Computing",
          "Grid Computing",
          "BOINC",
          "SPMD (Single Program, Multiple Data)",
          "Instruction-Level Parallelism (ILP)",
          "Superscalar",
          "VLIW (Very Long Instruction Word)",
          "EPIC (Explicitly Parallel Instruction Computing)",
          "Vector Processors",
          "Interconnection Networks",
          "Static Interconnection Network",
          "Dynamic Interconnection Network",
          "Crossbar Switch",
          "Multistage Interconnection Network",
          "Uniform Memory Access (UMA)",
          "Nonuniform Memory Access (NUMA)",
          "Cache Coherence",
          "Snoopy Cache",
          "Write-through Cache Policy",
          "Write-back Cache Policy",
          "Ubiquitous Computing",
          "Remote Procedure Call (RPC)",
          "SOAP (Simple Object Access Protocol)",
          "Cloud Computing",
          "Dataflow Computing",
          "Neural Network",
          "Perceptron",
          "Systolic Array",
          "Quantum Computing",
          "Qubit",
          "Superposition",
          "Shor's Algorithm",
          "Technological Singularity"
        ]
      },
      "flashcards": [
        {
          "question": "What is the primary philosophical difference between RISC and CISC architectures?",
          "answer": "RISC emphasizes a smaller, simpler, fixed-length instruction set for faster execution and easier pipelining, while CISC uses a larger, more complex, variable-length instruction set, often relying on microcode."
        },
        {
          "question": "According to Flynn's Taxonomy, which category describes a traditional uniprocessor system?",
          "answer": "SISD (Single Instruction Stream, Single Data Stream)."
        },
        {
          "question": "Which Flynn's Taxonomy category describes systems where a single instruction is executed simultaneously on multiple data values, like vector processors?",
          "answer": "SIMD (Single Instruction Stream, Multiple Data Streams)."
        },
        {
          "question": "What is the main challenge of shared memory multiprocessors (SMMs)?",
          "answer": "Cache coherence problems, where multiple processors might have inconsistent copies of data in their private caches."
        },
        {
          "question": "How do 'snoopy cache controllers' address cache coherence problems?",
          "answer": "They are hardware units that monitor bus traffic and invalidate or update copies of shared data in their respective caches when another processor modifies the main memory block."
        },
        {
          "question": "What is 'Grid Computing'?",
          "answer": "A form of distributed computing that utilizes networked computers (often via the Internet) across different administrative domains to solve large computational problems, leveraging unused resources."
        },
        {
          "question": "What is the core principle of 'dataflow computing'?",
          "answer": "Instructions execute only when all necessary input data (data tokens) becomes available, rather than following a sequential control flow defined by a program counter."
        },
        {
          "question": "What are 'neural networks' primarily inspired by, and what is their main application area?",
          "answer": "Inspired by the human brain, they are useful in dynamic situations without exact algorithmic solutions, primarily for pattern recognition, classification, and forecasting through 'learning' from data."
        },
        {
          "question": "What is a 'qubit' in quantum computing?",
          "answer": "The basic unit of quantum information, which, unlike a classical bit, can represent not only 0 or 1 but also exist in a superposition of both states simultaneously."
        },
        {
          "question": "What is 'superposition' in quantum computing?",
          "answer": "The ability of a qubit to exist in multiple states (e.g., both 0 and 1) simultaneously, enabling quantum parallelism and potentially revolutionizing computational speed."
        }
      ],
      "quiz": [
        {
          "question": "Which of the following is a characteristic of classical RISC design?",
          "options": {
            "A": "Many complex, variable-length instructions",
            "B": "Complexity handled primarily by microcode",
            "C": "On-chip register windows",
            "D": "Multiple-cycle instructions"
          },
          "correctAnswer": "C"
        },
        {
          "question": "Which type of interconnection network is fully connected and nonblocking but becomes very costly as the number of entities increases?",
          "options": {
            "A": "Bus-based network",
            "B": "Crossbar switch",
            "C": "Multistage interconnection network",
            "D": "Linear array network"
          },
          "correctAnswer": "B"
        },
        {
          "question": "A system where each processor has its own memory, but the entire memory space is contiguous and accessible, with varying access times based on proximity, is known as a:",
          "options": {
            "A": "UMA (Uniform Memory Access) system",
            "B": "SMP (Symmetric Multiprocessor) system",
            "C": "NUMA (Nonuniform Memory Access) machine",
            "D": "MPP (Massively Parallel Processor)"
          },
          "correctAnswer": "C"
        },
        {
          "question": "Which of the following describes a 'systolic array' computer?",
          "options": {
            "A": "A system where data availability drives instruction execution.",
            "B": "A neural network that learns from experience.",
            "C": "A network of processing elements that rhythmically compute data by circulating it through the system, ideal for repetitive tasks.",
            "D": "A quantum computer utilizing qubits for parallel computation."
          },
          "correctAnswer": "C"
        }
      ]
    },
    {
      "moduleTitle": "Module 10: Topics in Embedded Systems",
      "notes": {
        "summary": "This module provides an overview of embedded systems, which are specialized computer systems designed to perform dedicated functions within larger mechanical or electronic systems. Unlike general-purpose computers, embedded systems often operate with strict real-time constraints and resource limitations (time, space, power, price). The module implicitly covers aspects of embedded hardware, which can range from off-the-shelf microcontrollers to highly custom-designed or configurable hardware like FPGAs and ASICs. It also touches upon embedded software, which typically involves careful memory organization, the use of specialized embedded operating systems (RTOS) designed for efficiency and responsiveness, and unique software development challenges such as cross-compilation, debugging in resource-constrained environments, and ensuring reliability. Key concepts like watchdog timers, interrupt latency, and priority inversion, which are critical for real-time performance and system stability, are implicitly relevant to the design and operation of embedded systems.",
        "keywords": [
          "Embedded Systems",
          "Embedded Hardware",
          "Microcontroller",
          "Off-the-Shelf Hardware",
          "Configurable Hardware",
          "Custom-Designed Hardware",
          "Embedded Software",
          "Memory Organization (Embedded)",
          "Embedded Operating Systems (RTOS)",
          "Software Development (Embedded)",
          "Watchdog Timer",
          "Interrupt Latency",
          "Priority Inversion"
        ]
      },
      "flashcards": [
        {
          "question": "What is an embedded system?",
          "answer": "A specialized computer system designed to perform a dedicated function within a larger mechanical or electronic system, often with real-time constraints and limited resources."
        },
        {
          "question": "What is a 'watchdog timer' in an embedded system?",
          "answer": "A specialized circuit that periodically checks if the embedded system's software is still running correctly; if the software fails to reset the timer within a set interval, it triggers a system reset to recover from hangs or infinite loops."
        },
        {
          "question": "What is 'interrupt latency' in an embedded operating system?",
          "answer": "The time elapsed between an interrupt occurring and the execution of the first instruction of its corresponding interrupt service routine. It is a critical metric for real-time systems."
        },
        {
          "question": "What are RTOS (Real-Time Operating Systems) designed for?",
          "answer": "Embedded systems that require strict timing constraints and predictable response times for critical operations, often found in industrial control, robotics, and automotive applications."
        },
        {
          "question": "What is 'hardware/software codesign' in the context of embedded systems?",
          "answer": "A design methodology where hardware and software components of an embedded system are developed concurrently and co-dependently to optimize overall system performance and meet design constraints."
        }
      ],
      "quiz": [
        {
          "question": "Which of the following is a primary characteristic of embedded systems?",
          "options": {
            "A": "They are general-purpose computers for diverse tasks.",
            "B": "They typically have unlimited memory and processing power.",
            "C": "They are designed for dedicated functions within larger systems, often with resource constraints.",
            "D": "They always run full-featured desktop operating systems."
          },
          "correctAnswer": "C"
        },
        {
          "question": "A key challenge in embedded software development, especially for battery-powered devices, is:",
          "options": {
            "A": "Supporting unlimited concurrent user applications.",
            "B": "Minimizing power consumption and optimizing for limited memory.",
            "C": "Ensuring compatibility with all standard PC peripherals.",
            "D": "Maximizing graphical user interface complexity."
          },
          "correctAnswer": "B"
        }
      ]
    },
    {
      "moduleTitle": "Module 11: Performance Measurement and Analysis",
      "notes": {
        "summary": "This module covers the critical aspects of computer performance assessment and optimization. It begins by explaining the proper use of statistical measures—arithmetic, geometric, and harmonic means—for summarizing performance data, highlighting when each is appropriate. Benchmarking is then introduced as an objective method for performance evaluation, with a focus on impartial benchmarks from organizations like SPEC (Standard Performance Evaluation Corporation) and TPC (Transaction Processing Performance Council), discussing their design, interpretation, and limitations in reflecting real-world workloads. The utility of system simulation for predicting and optimizing performance in various configurations is also explored. A significant portion of the module is dedicated to CPU performance optimization techniques. This includes strategies for branch optimization (delayed branching, static and dynamic branch prediction, speculative execution) to mitigate pipeline stalls caused by conditional jumps. It also emphasizes the importance of good algorithms and simple code, along with specific loop optimization techniques such as loop unrolling, loop fusion, loop fission (splitting/peeling), and loop interchange, all aimed at improving instruction-level parallelism and memory access patterns. Finally, the module addresses disk performance, explaining its substantial impact on overall system throughput. It covers understanding disk utilization and queuing theory, physical considerations (seek time, rotational delay, transfer rate), and logical considerations like disk scheduling algorithms (FCFS, SSTF, SCAN, C-SCAN, LOOK, C-LOOK), file placement, fragmentation, and the use of disk caching and prefetching, along with the complexities of write caching issues.",
        "keywords": [
          "Performance Measurement",
          "Arithmetic Mean",
          "Geometric Mean",
          "Harmonic Mean",
          "Benchmarking",
          "SPEC",
          "TPC",
          "System Simulation",
          "CPU Optimization",
          "Branch Optimization",
          "Delayed Branching",
          "Branch Prediction",
          "Static Prediction",
          "Dynamic Prediction",
          "Speculative Execution",
          "Loop Optimization",
          "Loop Unrolling",
          "Loop Fusion",
          "Loop Fission",
          "Loop Interchange",
          "Disk Performance",
          "Disk Utilization",
          "Seek Time",
          "Rotational Delay",
          "Access Time",
          "Transfer Rate",
          "Disk Scheduling",
          "FCFS (First-Come, First-Served)",
          "SSTF (Shortest Seek Time First)",
          "SCAN (Elevator Algorithm)",
          "C-SCAN (Circular SCAN)",
          "LOOK",
          "C-LOOK",
          "Disk Fragmentation",
          "Disk Caching",
          "Prefetching",
          "Write Caching"
        ]
      },
      "flashcards": [
        {
          "question": "Which type of statistical mean is most appropriate for averaging rates or ratios in computer performance analysis?",
          "answer": "Harmonic Mean."
        },
        {
          "question": "What is the primary purpose of 'benchmarking' in computer systems?",
          "answer": "To objectively assess the performance of hardware or software systems under a defined workload, providing a basis for comparison and gauging improvements."
        },
        {
          "question": "What is a 'pipeline stall' or 'hazard' in CPU performance?",
          "answer": "A condition that prevents a pipelined CPU from executing one instruction per clock cycle, often caused by resource conflicts, data dependencies, or conditional branches."
        },
        {
          "question": "What is 'branch prediction' in CPU optimization?",
          "answer": "A technique where the processor attempts to guess the outcome of a conditional branch instruction before it is fully executed, to avoid pipeline stalls; incorrect predictions require flushing the pipeline."
        },
        {
          "question": "Explain 'speculative execution' in pipelining.",
          "answer": "Executing instructions ahead of a conditional branch before their necessity is confirmed. If the branch prediction is incorrect, the speculative work must be undone."
        },
        {
          "question": "What is 'loop unrolling'?",
          "answer": "A loop optimization technique that expands a loop by performing several original iterations per new iteration, reducing loop overhead and enabling better instruction scheduling and parallelism."
        },
        {
          "question": "What is 'disk utilization'?",
          "answer": "A key I/O performance metric measuring the percentage of time a disk is busy servicing requests, or the probability that the disk is busy when a new request arrives."
        },
        {
          "question": "What is the main goal of 'disk scheduling algorithms'?",
          "answer": "To minimize the total disk arm motion (seek time) by optimizing the order in which pending disk access requests are serviced."
        },
        {
          "question": "Which disk scheduling algorithm services requests by moving the disk arm in one direction, servicing all requests in its path, then reversing direction (like an elevator)?",
          "answer": "SCAN (or Elevator Algorithm)."
        },
        {
          "question": "What is 'prefetching' in the context of disk caching?",
          "answer": "A technique where a disk reads subsequent sectors to the requested one, anticipating that they will be needed soon, leveraging spatial and sequential locality to reduce future access times."
        }
      ],
      "quiz": [
        {
          "question": "Which type of mean is best for comparing the relative performance of two systems where the individual measurements are normalized to a reference machine?",
          "options": {
            "A": "Arithmetic Mean",
            "B": "Geometric Mean",
            "C": "Harmonic Mean",
            "D": "Weighted Average"
          },
          "correctAnswer": "B"
        },
        {
          "question": "Which type of branch prediction uses a buffer to store the history of previous branch outcomes?",
          "options": {
            "A": "Fixed prediction",
            "B": "Static prediction",
            "C": "Dynamic prediction",
            "D": "Delayed branching"
          },
          "correctAnswer": "C"
        },
        {
          "question": "Which loop optimization technique involves combining loops that use the same data items?",
          "options": {
            "A": "Loop Unrolling",
            "B": "Loop Fission",
            "C": "Loop Fusion",
            "D": "Loop Peeling"
          },
          "correctAnswer": "C"
        },
        {
          "question": "Why is it generally recommended to keep disk utilization below 80%?",
          "options": {
            "A": "To save electricity.",
            "B": "To prevent physical damage to the disk.",
            "C": "Because disk queue time increases exponentially beyond this point, leading to severe performance degradation.",
            "D": "To ensure data redundancy."
          },
          "correctAnswer": "C"
        }
      ]
    },
    {
      "moduleTitle": "Module 12: Network Organization and Architecture",
      "notes": {
        "summary": "This module provides a comprehensive overview of network organization and architecture, tracing the evolution from early business (IBM's SNA) and academic (ARPAnet, NSFnet, Internet) networks. It details network protocols, with a strong focus on the theoretical ISO/OSI Reference Model (seven layers: Physical, Data Link, Network, Transport, Session, Presentation, Application) and the practical TCP/IP protocol suite (IP, TCP). Key distinctions and functions of each layer are explained, along with the concept of Protocol Data Units (PDUs) and Service Access Points (SAPs). The module highlights the critical issues with IPv4, particularly address scarcity and routing overhead, and introduces IPv6 as the solution, detailing its vastly expanded 128-bit address space, hierarchical organization, and built-in security features. Network organization types (LAN, MAN, WAN) are defined, and various physical transmission media are examined, including coaxial cable, twisted pair, fiber-optic cable (single-mode, multimode), and wireless technologies (Bluetooth, WLAN). Essential network components are discussed, such as Network Interface Cards (NICs), repeaters, hubs, switches, bridges, gateways, and routers. Special attention is given to router functionality and routing algorithms (static, dynamic, distance vector, link state), including common problems like 'count-to-infinity' and their solutions. Finally, the module addresses the growing fragility of the Internet due to cyber warfare and the massive influx of 'Internet of Things' (IoT) devices, leading to concerns about congestive collapse, and suggests the need for more intelligent routing.",
        "keywords": [
          "Network Organization",
          "Network Architecture",
          "IBM SNA",
          "ARPAnet",
          "Internet",
          "Network Protocols",
          "ISO/OSI Reference Model",
          "TCP/IP Protocol Suite",
          "Physical Layer",
          "Data Link Layer",
          "Network Layer",
          "Transport Layer",
          "Session Layer",
          "Presentation Layer",
          "Application Layer",
          "Protocol Data Unit (PDU)",
          "Service Access Point (SAP)",
          "IPv4",
          "IPv6",
          "Datagram",
          "Port",
          "Socket",
          "Flow Control",
          "LAN (Local Area Network)",
          "MAN (Metropolitan Area Network)",
          "WAN (Wide Area Network)",
          "Coaxial Cable",
          "Twisted Pair",
          "Fiber-Optic Cable",
          "Wireless Communication",
          "Bluetooth",
          "WLAN (Wireless Local Area Network)",
          "Network Interface Card (NIC)",
          "MAC Address",
          "Repeater",
          "Hub",
          "Switch",
          "Bridge",
          "Gateway",
          "Router",
          "Routing Algorithms",
          "Static Routing",
          "Dynamic Routing",
          "Distance Vector Routing",
          "Link State Routing",
          "Count-to-Infinity Problem",
          "Cyber Warfare",
          "Internet of Things (IoT)",
          "Congestive Collapse",
          "Firewall"
        ]
      },
      "flashcards": [
        {
          "question": "What is the purpose of the ISO/OSI Reference Model?",
          "answer": "It is a comprehensive theoretical model that divides network communication into seven distinct layers, standardizing protocols and facilitating interoperability between different systems."
        },
        {
          "question": "Which two layers of the OSI model are most closely mapped to the TCP/IP's IP layer?",
          "answer": "OSI's Network Layer and Data Link Layer."
        },
        {
          "question": "What is the primary limitation of IPv4 addressing?",
          "answer": "The limited 32-bit address space (approximately 4.3 billion unique addresses) which has led to address scarcity and complex management issues as the Internet has grown."
        },
        {
          "question": "What is the most significant improvement in IPv6 over IPv4?",
          "answer": "Its vastly extended 128-bit address space, providing an effectively inexhaustible supply of unique IP addresses."
        },
        {
          "question": "What is a 'socket' in TCP/IP networking?",
          "answer": "The combination of a port number, a host ID (IP address), and the protocol (TCP or UDP), which uniquely identifies an application's communication endpoint."
        },
        {
          "question": "What is the primary function of a 'router'?",
          "answer": "A Layer 3 network device that determines where to forward packets between different networks based on logical addresses and routing tables, calculating optimal paths."
        },
        {
          "question": "What is the 'count-to-infinity problem' in distance vector routing?",
          "answer": "A problem where routing loops can occur, and old, invalid routes persist indefinitely because routers continue to increment the 'distance' to unreachable networks, eventually leading to network instability or crash."
        },
        {
          "question": "What is 'fiber-optic cable'?",
          "answer": "A guided transmission medium composed of thin glass or plastic strands that transmit data as light pulses, offering very high bandwidth and immunity to electromagnetic interference."
        },
        {
          "question": "What is the 'Internet of Things' (IoT)?",
          "answer": "The concept of connecting a vast number of devices (sensors, appliances, industrial controls) beyond traditional computers to the Internet, enabling machine-to-machine (M2M) communication and data exchange."
        },
        {
          "question": "What is 'congestive collapse' in the context of the Internet?",
          "answer": "A worst-case scenario where significant numbers of routers go offline due to their inability to handle the incoming traffic load, leading to widespread network failure."
        }
      ],
      "quiz": [
        {
          "question": "Which OSI layer is responsible for organizing message bytes into frames and handling flow control?",
          "options": {
            "A": "Physical Layer",
            "B": "Data Link Layer",
            "C": "Network Layer",
            "D": "Transport Layer"
          },
          "correctAnswer": "B"
        },
        {
          "question": "What does TCP (Transmission Control Protocol) primarily provide?",
          "options": {
            "A": "Unreliable, connectionless packet delivery.",
            "B": "A simple way to route datagrams between networks.",
            "C": "Reliable, connection-oriented data stream service with sequencing and error correction.",
            "D": "Direct hardware interface for network communication."
          },
          "correctAnswer": "C"
        },
        {
          "question": "Which physical transmission medium offers the highest bandwidth and immunity to electromagnetic interference?",
          "options": {
            "A": "Coaxial Cable",
            "B": "Twisted Pair",
            "C": "Fiber-Optic Cable",
            "D": "Wireless (Bluetooth)"
          },
          "correctAnswer": "C"
        },
        {
          "question": "Which network device is primarily a Layer 2 device that creates point-to-point connections between input and output ports, handling multiple simultaneous communications?",
          "options": {
            "A": "Repeater",
            "B": "Hub",
            "C": "Switch",
            "D": "Router"
          },
          "correctAnswer": "C"
        }
      ]
    },
    {
      "moduleTitle": "Module 13: Selected Storage Systems and Interfaces",
      "notes": {
        "summary": "This module examines various I/O architectures and storage system implementations, focusing on how they meet the growing demand for data storage and management. It begins with the Small Computer System Interface (SCSI), detailing its evolution from classic parallel SCSI to the layered SCSI Architecture Model-3 (SAM-3), which supports diverse serial protocols like IEEE 1394 (FireWire), Serial Storage Architecture (SSA), and Fibre Channel (FC). Fibre Channel, a high-speed serial technology, is discussed with its various topologies (switched, point-to-point, FC-AL) and service classes. The module introduces Internet SCSI (iSCSI) as a cost-effective alternative that encapsulates SCSI commands over TCP/IP networks. Storage Area Networks (SANs) are presented as dedicated high-speed networks for storage access, contrasting them with Network Attached Storage (NAS) by highlighting SANs' superior performance due to bypassing traditional file servers. Other significant I/O connections are covered, including parallel buses like ATA (and its evolution to EIDE), the serial counterparts Serial ATA (SATA) and Serial Attached SCSI (SAS), and the high-performance Peripheral Component Interconnect (PCI) bus. The Universal Serial Bus (USB) is thoroughly explained, detailing its versions, components (root/multiport hubs), plug-and-play functionality, and various data transfer modes. Finally, the module concludes with Cloud Storage, differentiating between consumer and enterprise-grade services, discussing Service-Level Agreements (SLAs) and Total Cost of Ownership (TCO), and addressing the inherent risks and challenges (availability, security, regulations) associated with outsourcing data storage to the cloud.",
        "keywords": [
          "Storage Systems",
          "I/O Interfaces",
          "SCSI (Small Computer System Interface)",
          "SCSI Architecture Model-3 (SAM-3)",
          "Parallel SCSI",
          "IEEE 1394 (FireWire)",
          "Serial Storage Architecture (SSA)",
          "Fibre Channel (FC)",
          "Fibre Channel Arbitrated Loop (FC-AL)",
          "Switched Fabric",
          "Internet SCSI (iSCSI)",
          "Storage Area Network (SAN)",
          "Network Attached Storage (NAS)",
          "ATA (AT Attachment)",
          "EIDE (Enhanced Integrated Drive Electronics)",
          "Serial ATA (SATA)",
          "Serial Attached SCSI (SAS)",
          "PCI (Peripheral Component Interconnect)",
          "USB (Universal Serial Bus)",
          "USB On-the-Go (USB OTG)",
          "Plug-and-Play",
          "Cloud Storage",
          "Service-Level Agreement (SLA)",
          "Total Cost of Ownership (TCO)"
        ]
      },
      "flashcards": [
        {
          "question": "What was the groundbreaking idea behind the original SCSI interface?",
          "answer": "To embed intelligence directly into the interface for self-management, thereby freeing the CPU from I/O control and allowing it to focus on computation."
        },
        {
          "question": "What is the primary benefit of Fibre Channel Arbitrated Loop (FC-AL) topology?",
          "answer": "It is the most widely used and least costly loop topology for Fibre Channel, allowing up to 127 devices (practically 60) to communicate at 100MBps with built-in failover capabilities."
        },
        {
          "question": "How does Internet SCSI (iSCSI) work?",
          "answer": "It capitalizes on existing Internet and LAN protocols by encapsulating SCSI commands and data within TCP/IP packets, allowing SCSI storage to be accessed over standard Ethernet networks."
        },
        {
          "question": "What is the main advantage of a Storage Area Network (SAN) over Network Attached Storage (NAS)?",
          "answer": "SANs are dedicated networks for storage access that bypass traditional file servers, resulting in leaner, faster access to storage devices because they don't incur typical network protocol overhead."
        },
        {
          "question": "Why is the industry shifting from parallel ATA to Serial ATA (SATA)?",
          "answer": "SATA offers faster transfer rates, lower voltage requirements, longer cables, enhanced error checking, and a point-to-point configuration that enables concurrent data transfers, addressing bottlenecks and heat issues of parallel ATA."
        },
        {
          "question": "What is the Universal Serial Bus (USB) known for?",
          "answer": "Its universality as an external peripheral interface supporting plug-and-play functionality, hot plugging, various data transfer modes, and power delivery, making it widely adopted across electronic devices."
        },
        {
          "question": "What is 'USB On-the-Go (USB OTG)'?",
          "answer": "A USB feature that allows a single device to act as either a host (e.g., connecting a keyboard to a tablet) or a slave (e.g., connecting the tablet to a desktop PC), depending on the connection."
        },
        {
          "question": "What is 'Cloud Storage'?",
          "answer": "A service that provides scalable data storage accessible via the Internet, where users pay for capacity on demand, relying on a third-party provider for infrastructure and management."
        },
        {
          "question": "What are 'Service-Level Agreements (SLAs)' in the context of enterprise-class Cloud storage?",
          "answer": "Contracts between a cloud storage provider and a client that define agreed-upon performance requirements (e.g., availability, reliability, responsiveness) and often specify monetary penalties for unmet parameters."
        },
        {
          "question": "What is the primary impediment to widespread adoption of enterprise-class Cloud storage?",
          "answer": "Security concerns, as many organizations are hesitant to cede full control over their critical data to an outside company, and regulatory compliance can be challenging."
        }
      ],
      "quiz": [
        {
          "question": "Which SCSI standard is the current layered specification that separates physical connections from transport protocols and interface commands?",
          "options": {
            "A": "SCSI-1",
            "B": "SCSI-2",
            "C": "SCSI Architecture Model-3 (SAM-3)",
            "D": "Ultra SCSI-3"
          },
          "correctAnswer": "C"
        },
        {
          "question": "Which Fibre Channel topology offers the most bandwidth and virtually no device limit, but is also the most costly?",
          "options": {
            "A": "Point-to-point",
            "B": "FC-AL (Fibre Channel Arbitrated Loop)",
            "C": "Switched Fabric",
            "D": "SSA Loop"
          },
          "correctAnswer": "C"
        },
        {
          "question": "Which interface is a serial version of SCSI that shares the same plugs/cabling as SATA but is designed for higher scalability and enterprise use?",
          "options": {
            "A": "EIDE",
            "B": "PCI",
            "C": "USB",
            "D": "Serial Attached SCSI (SAS)"
          },
          "correctAnswer": "D"
        },
        {
          "question": "What is a major downside or risk associated with Cloud Storage?",
          "options": {
            "A": "Guaranteed 100% data availability.",
            "B": "Unlimited free storage space.",
            "C": "Loss of direct control over data security and reliance on contract enforcement.",
            "D": "Faster local network speeds."
          },
          "correctAnswer": "C"
        }
      ]
    },
    {
      "moduleTitle": "Module 14: Introduction to Data Structures",
      "notes": {
        "summary": "This appendix module provides a concise introduction and review of fundamental data structures that are essential for understanding how data is organized and manipulated within computer systems. It covers common linear data structures such as arrays, which are collections of elements identified by an index; queues, which follow a First-In, First-Out (FIFO) principle; and linked lists, which consist of elements (nodes) containing data and a pointer to the next element, allowing for flexible memory allocation. Stacks, operating on a Last-In, First-Out (LIFO) principle, are also discussed. The module then introduces non-linear data structures like trees, which are hierarchical structures with a root node, internal nodes, and leaf nodes, often used for efficient searching and sorting. Finally, it briefly touches upon network graphs, which represent relationships between entities using nodes and edges. Understanding these data structures is fundamental for writing efficient algorithms and comprehending the underlying organization of software and its interaction with hardware memory.",
        "keywords": [
          "Data Structures",
          "Array",
          "Queue",
          "Linked List",
          "Stack",
          "Tree",
          "Network Graph",
          "FIFO (First-In, First-Out)",
          "LIFO (Last-In, First-Out)"
        ]
      },
      "flashcards": [
        {
          "question": "What is a 'queue' data structure?",
          "answer": "A linear data structure that operates on a First-In, First-Out (FIFO) principle, meaning the first element added is the first one to be removed."
        },
        {
          "question": "What is a 'stack' data structure?",
          "answer": "A linear data structure that operates on a Last-In, First-Out (LIFO) principle, meaning the last element added is the first one to be removed."
        },
        {
          "question": "What is a 'linked list'?",
          "answer": "A data structure where elements are stored non-contiguously, with each element (node) containing a data part and a pointer (or link) to the next element in the sequence."
        },
        {
          "question": "What is a 'binary tree'?",
          "answer": "A hierarchical data structure where each node has at most two children, typically referred to as the left child and the right child."
        },
        {
          "question": "What is the key characteristic of an 'array' data structure?",
          "answer": "It is a collection of elements of the same data type stored in contiguous memory locations, accessed using an index."
        }
      ],
      "quiz": [
        {
          "question": "Which data structure follows the First-In, First-Out (FIFO) principle?",
          "options": {
            "A": "Stack",
            "B": "Queue",
            "C": "Linked List",
            "D": "Tree"
          },
          "correctAnswer": "B"
        },
        {
          "question": "Which of the following is characteristic of a 'stack'?",
          "options": {
            "A": "Elements are accessed by an index.",
            "B": "It operates on a Last-In, First-Out (LIFO) principle.",
            "C": "Elements are stored non-contiguously with pointers.",
            "D": "It is primarily used for hierarchical data representation."
          },
          "correctAnswer": "B"
        },
        {
          "question": "A data structure where each element points to the next, allowing for dynamic memory allocation, is a(n):",
          "options": {
            "A": "Array",
            "B": "Queue",
            "C": "Linked List",
            "D": "Stack"
          },
          "correctAnswer": "C"
        },
        {
          "question": "Which data structure is typically used to represent hierarchical relationships?",
          "options": {
            "A": "Queue",
            "B": "Array",
            "C": "Linked List",
            "D": "Tree"
          },
          "correctAnswer": "D"
        }
      ]
    }
  ]
}
```